# **ImpRes: Implicit Residual Diffusion Models for Image Super-Resolution**
This repository is dedicated to the project "ImpRes: Implicit Residual Diffusion Models for Image Super-Resolution" by Shiyun Zhang, Xing Deng, Haijian Shao, and others. The project introduces an innovative approach to Single Image Super-Resolution (SISR) using Implicit Residual Diffusion Models.

## Overview   
The ImpRes model addresses common challenges in SISR, such as high-frequency texture distortion, excessive smoothing, and scale inconsistency. It enhances model convergence speed and high-frequency detail recovery through a residual prediction mechanism. Additionally, it employs a high-frequency guidance module and Static Implicit Neural Representation (SINR) to achieve precise content perception and mitigate over-smoothing.

## Key Features
Residual Prediction Mechanism: Improves model convergence and detail recovery.
High-Frequency Guidance Module: Uses Gaussian high-pass filters to emphasize high-frequency components.
Static Implicit Neural Representation (SINR): Transforms discrete image representations into a continuous local implicit image function for precise perception and flexible sampling.
State-of-the-Art Performance: Outperforms current diffusion-based methods in model convergence time, generation quality, and scale consistency.
Performance
In 4Ã— face super-resolution tasks, ImpRes achieves a peak signal-to-noise ratio of 29.97 dB.

## Code Availability
The code for this project is currently being prepared for release. We are in the process of finalizing the manuscript and will make the code publicly available upon acceptance of the paper.

## Contact   
For any inquiries or collaboration opportunities, please contact the author, Shiyun Zhang, at fineverse@163.com.

## Acknowledgements   
We would like to thank all the contributors and supporters of this project.

## Disclaimer
This repository is a placeholder for the upcoming code release. The actual code will be uploaded after the paper has been accepted for publication.
